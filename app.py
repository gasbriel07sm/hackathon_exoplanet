# app.py

import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from model import ExoplanetModel

# --- CONFIGURA√á√ïES DA P√ÅGINA E ESTILO ---
st.set_page_config(page_title="Exoplanet Detector AI", layout="wide", initial_sidebar_state="expanded")
sns.set_theme(style="whitegrid", palette="viridis")

# --- CSS CUSTOMIZADO PARA O SELETOR DE IDIOMA COM HOVER ---
st.markdown("""
<style>
.language-selector {
    position: relative;
    display: inline-block;
    width: 100%;
    margin-bottom: 10px; /* Adiciona espa√ßo abaixo */
}

.language-button {
    background-color: #222;
    color: white;
    padding: 10px 15px;
    font-size: 16px;
    border: 1px solid #444;
    border-radius: 0.5rem;
    cursor: default;
    width: 100%;
    text-align: left;
}

.language-dropdown {
    display: none;
    position: absolute;
    background-color: #f1f1f1;
    min-width: 100%;
    box-shadow: 0px 8px 16px 0px rgba(0,0,0,0.2);
    z-index: 1;
    border-radius: 0.5rem;
}

.language-dropdown a {
    color: black;
    padding: 12px 16px;
    text-decoration: none;
    display: block;
    font-size: 16px;
}

.language-dropdown a:hover {background-color: #ddd;}
.language-selector:hover .language-dropdown {display: block;}
</style>
""", unsafe_allow_html=True)

# --- DICION√ÅRIO DE TRADU√á√ïES (i18n) - VERS√ÉO EXPANDIDA ---
translations = {
    'en': {
        # ... Metadados da UI
        "sidebar_title": "üõ∞Ô∏è Exoplanet Detector",
        "sidebar_subtitle": "An AI to classify objects of interest based on NASA data.",
        "sidebar_select_mode": "Choose your tool:",
        "mode_classifier": "AI Classifier",
        "mode_analysis": "Data Analysis",
        "mode_reference": "Reference Guide",
        "lang_current": "üá¨üáß English",
        "lang_switch_to": "üáßüá∑ Portugu√™s",
        "lang_switch_code": "pt",

        # ... Textos do Classificador
        "classifier_title": "Exoplanet Classification Panel",
        "classifier_tab_file": "Classify by File",
        "classifier_tab_manual": "Classify Manually",
        "file_uploader_label": "Choose a CSV file with candidate data:",
        "example_button": "Use a Random Example",
        "classify_file_button": "Classify Object from File",
        "manual_header": "Insert data manually (key features)",
        "classify_manual_button": "Classify with Manual Data",
        "form_koi_score": "KOI Score",
        "form_koi_period": "Orbital Period [days]",
        "form_koi_prad": "Planetary Radius [Earth radii]",
        "form_koi_duration": "Transit Duration [hours]",
        "form_koi_depth": "Transit Depth [ppm]",
        "form_koi_teq": "Equilibrium Temp. [K]",
        "spinner_text": "Analyzing data with the AI...",
        "analysis_finished": "‚úÖ Analysis Complete!",
        "result_header": "Classification Result:",
        "confidence_header": "Confidence Level:",
        "class_candidate": "Candidate",
        "class_confirmed": "Confirmed",
        "class_false_positive": "False Positive",
        "warning_ia": "‚ö†Ô∏è **AI Warning:** {}",
        "error_prediction": "‚ùå Prediction Error: {}",
        "example_success": "Random example loaded!",
        "sample_data_header": "Sample of uploaded data:",
        "example_data_header": "Using a random example:",
        "file_read_error": "Error reading CSV file: {}",


        # ... Textos de An√°lise de Dados
        "analysis_title": "Exploratory Data Analysis",
        "analysis_subtitle": "Visualizing the Kepler dataset to uncover patterns and understand the foundation upon which our AI was trained.",
        "analysis_chart1_title": "Exoplanet Dispositions in the Dataset",
        "analysis_chart1_desc": """
        This bar chart shows the distribution of the three main classes in our dataset. We can observe a significant class imbalance:
        - **False Positives** are the most common class, which is expected. The vast majority of signals detected by telescopes are not actual planets.
        - **Candidates** represent a smaller, but still significant, portion of promising signals.
        - **Confirmed** planets are the rarest class, as they require extensive verification.
        This imbalance is a key reason why techniques like SMOTE were used during the AI's training to ensure it learns to identify the rare classes effectively.
        """,
        "analysis_chart2_title": "Orbital Period vs. Planetary Radius",
        "analysis_chart2_desc": """
        This scatter plot reveals the relationship between a planet's "year" (orbital period) and its size (radius). Both axes are on a logarithmic scale to better visualize the wide range of values.
        - We can see a dense cluster of planets with short orbital periods (less than 100 days), which are easier to detect because they transit their star more frequently.
        - There is no simple linear relationship, indicating that planets of all sizes can be found at various distances from their stars. The confirmed planets, represented by one of the colors in the legend, are scattered across the plot, highlighting the diversity of discovered worlds.
        """,
        "analysis_chart3_title": "Distribution of Stellar Equilibrium Temperatures",
        "analysis_chart3_desc": """
        This histogram displays the frequency of different stellar effective temperatures in the dataset. This temperature is a proxy for the type of star being observed.
        - The distribution peaks around 5500-6000 Kelvin, which is very similar to our Sun (~5,778 K). This indicates that the Kepler mission was particularly effective at observing Sun-like stars (G-type main-sequence stars).
        - This focus is partly by design, as Sun-like stars are of high interest in the search for potentially habitable exoplanets.
        """,
        "analysis_chart4_title": "What Does the AI Consider Most Important?",
        "analysis_chart4_desc": """
        This chart displays the **feature importances** as determined by our trained XGBoost model. It essentially shows which data columns the AI relies on most to make its classification decision.
        - Unsurprisingly, `koi_score` (a pre-computed score of how likely a signal is to be a planet) is the most influential feature.
        - The various `koi_fpflag` (False Positive Flags) are also highly important. These are flags assigned by the Kepler pipeline that indicate if a signal resembles known types of false positives.
        - By visualizing this, we gain trust in our model, as it confirms that the AI is focusing on the most scientifically relevant variables to distinguish real planets from impostors.
        """,
        "analysis_chart1_xlabel": "Disposition Class",
        "analysis_chart1_ylabel": "Number of Samples",
        "analysis_chart2_xlabel": "Orbital Period [log scale, days]",
        "analysis_chart2_ylabel": "Planetary Radius [log scale, Earth radii]",
        "analysis_chart3_xlabel": "Equilibrium Temperature [K]",
        "analysis_chart3_ylabel": "Frequency",
        "analysis_chart4_xlabel": "Importance Score",
        "analysis_chart4_ylabel": "Feature Name",

        # ... Textos do Guia de Refer√™ncia
        "ref_title": "Reference Guide: Understanding Exoplanets and Our AI",
        "ref_pipeline_title": "How Does Our AI Work? The Pipeline Step-by-Step",
        "ref_pipeline_text": """
        To ensure every new piece of data is analyzed consistently and accurately, our AI uses a **Machine Learning Pipeline**. This is a sequence of automated steps that process data from its raw form to a final prediction. Here's how it works:
        
        **During Training (what we did once):**
        1.  **Data Ingestion & Unification:** We loaded data from multiple NASA missions (Kepler, K2, TESS) and merged them into a single, massive dataset.
        2.  **Preparation & Splitting:** We separated the data into features (the inputs, e.g., `koi_period`) and the target (the output we want to predict, `disposition`). This data was then split into a training set (to teach the AI) and a test set (to evaluate it).
        3.  **Preprocessing:** The training data went through a rigorous "treatment" process:
            - **Imputation:** Filled in any missing data points using the median value of each column.
            - **Label Encoding:** Converted text labels ('Candidate', 'Confirmed') into numbers (0, 1, 2) that the model can understand.
            - **SMOTE (Balancing):** Since 'Confirmed' planets are rare, this technique created intelligent synthetic examples of the rare classes to prevent the AI from becoming biased towards 'False Positives'.
            - **Scaling:** Normalized all numeric features to a common scale, ensuring no single feature could unfairly dominate the learning process.
        4.  **Model Training:** Our core model, an **XGBoost Classifier**, was trained on this fully preprocessed data.
        5.  **Artifact Serialization:** We saved not just the trained model, but *every single component* of the preprocessing pipeline (the imputer, the scaler, the label encoder, and the column list). These are the 'artifacts'.

        **During Prediction (what happens every time you click 'Classify'):**
        1.  **Load Artifacts:** The application loads all the saved components of the pipeline.
        2.  **Apply Identical Pipeline:** Your new data is passed through the exact same sequence of steps, using the already-fitted components:
            - The **fitted imputer** fills missing values based on the original data's medians.
            - The **fitted scaler** normalizes your data based on the original data's scale.
            - The **trained XGBoost model** receives the fully processed data and makes a prediction.
            - The **fitted label encoder** translates the model's numeric output back into a human-readable label ('Candidate', 'Confirmed', or 'False Positive').
            
        This strict, repeatable process ensures that every prediction is made with the same rigor and logic that was used to train and validate the AI.
        """,
        "ref_performance_title": "Our AI's Performance",
        "ref_performance_text": """
        To ensure our model is reliable, it was rigorously evaluated on a separate test set of data that it had never seen during training. Based on the final evaluation in our training notebook, the model achieved:
        - **Overall Accuracy: 98.46%**
        This high accuracy score means the model is extremely effective at correctly classifying signals into 'Confirmed', 'Candidate', and 'False Positive' categories. This level of performance is crucial for efficiently filtering through vast amounts of data to find genuine exoplanet signals.
        """,
        "ref_what_are_exoplanets_title": "What are Exoplanets?",
        "ref_what_are_exoplanets_text": """
        An exoplanet is any planet beyond our solar system. They come in a wide variety of sizes and orbits. Some are gigantic gas-giants hugging their parent star, others are icy, and some are rocky, like Earth. As of 2024, more than 5,000 exoplanets have been found. Key types include:
        - **Gas Giants:** Large planets composed mostly of helium and/or hydrogen, like Jupiter and Saturn.
        - **Super-Earths:** A class of planets with a mass higher than Earth's, but substantially below those of the Solar System's ice giants, Uranus and Neptune.
        - **Neptune-like:** Planets similar in size to Neptune or Uranus, with hydrogen/helium-dominated atmospheres.
        - **Terrestrial:** Earth-sized or smaller planets, composed of rock, silicate, water or carbon. The search for habitable worlds focuses on this category.
        """,
        "ref_how_ai_helps_title": "How Does Our AI Help?",
        "ref_how_ai_helps_text": """
        Manually analyzing hundreds of thousands of light curves is impossible. Our AI automates and accelerates this process. Specifically, it is a **XGBoost (Extreme Gradient Boosting) model**, a powerful machine learning algorithm.
        
        1.  **Pattern Recognition:** The XGBoost model is an ensemble of "decision trees". It learns by sequentially adding new trees that correct the errors of the previous ones. This allows it to learn highly complex and non-linear patterns in the transit data that a human eye would miss.
        2.  **Feature Importance:** It can determine which of the hundreds of features (like transit depth, stellar radius, etc.) are most predictive for classifying a signal. We can see in the 'Data Analysis' tab that features like `koi_score` are highly influential.
        3.  **Speed and Efficiency:** Once trained, the model can classify a new candidate in a fraction of a second. This allows scientists to efficiently sift through massive datasets from missions like TESS and prioritize the most promising signals for follow-up verification with other telescopes. It acts as an incredibly effective, intelligent filter.
        """,
        "ref_dispositions_title": "Understanding the Classifications",
        "ref_dispositions_text": """
        - **Candidate:** A signal that has passed initial automated tests and exhibits planet-like characteristics. It's a promising lead, but not yet a confirmed planet. The AI's job is to assess the strength of this candidacy.
        - **False Positive:** A signal that mimics a planetary transit but is caused by something else. Common causes include eclipsing binary star systems (two stars orbiting each other), starspots, or noise from the spacecraft's instruments. A robust AI is crucial for weeding these out with high accuracy.
        - **Confirmed:** A candidate that has been verified as a true exoplanet through rigorous follow-up observations, often using different detection methods (like the radial velocity method) to confirm its mass and planetary nature.
        """,
    },
    'pt': {
        # ... Metadados da UI
        "sidebar_title": "üõ∞Ô∏è Detector de Exoplanetas",
        "sidebar_subtitle": "Uma IA para classificar objetos de interesse com base em dados da NASA.",
        "sidebar_select_mode": "Escolha a sua ferramenta:",
        "mode_classifier": "Classificador IA",
        "mode_analysis": "An√°lise de Dados",
        "mode_reference": "Guia de Refer√™ncia",
        "lang_current": "üáßüá∑ Portugu√™s",
        "lang_switch_to": "üá¨üáß English",
        "lang_switch_code": "en",

        # ... Textos do Classificador
        "classifier_title": "Painel de Classifica√ß√£o de Exoplanetas",
        "classifier_tab_file": "Classificar por Ficheiro",
        "classifier_tab_manual": "Classificar Manualmente",
        "file_uploader_label": "Escolha um ficheiro CSV com os dados do candidato:",
        "example_button": "Usar um Exemplo Aleat√≥rio",
        "classify_file_button": "Classificar Objeto do Ficheiro",
        "manual_header": "Inserir dados manualmente (principais caracter√≠sticas)",
        "classify_manual_button": "Classificar com Dados Manuais",
        "form_koi_score": "Score KOI",
        "form_koi_period": "Per√≠odo Orbital [dias]",
        "form_koi_prad": "Raio Planet√°rio [raios terrestres]",
        "form_koi_duration": "Dura√ß√£o do Tr√¢nsito [horas]",
        "form_koi_depth": "Profundidade do Tr√¢nsito [ppm]",
        "form_koi_teq": "Temp. de Equil√≠brio [K]",
        "spinner_text": "A analisar os dados com a IA...",
        "analysis_finished": "‚úÖ An√°lise Conclu√≠da!",
        "result_header": "Resultado da Classifica√ß√£o:",
        "confidence_header": "N√≠vel de Confian√ßa:",
        "class_candidate": "Candidato",
        "class_confirmed": "Confirmado",
        "class_false_positive": "Falso Positivo",
        "warning_ia": "‚ö†Ô∏è **Aviso da IA:** {}",
        "error_prediction": "‚ùå Erro na previs√£o: {}",
        "example_success": "Exemplo aleat√≥rio carregado!",
        "sample_data_header": "Amostra dos dados enviados:",
        "example_data_header": "A usar um exemplo aleat√≥rio:",
        "file_read_error": "Erro ao ler o ficheiro CSV: {}",
        
        # ... Textos de An√°lise de Dados
        "analysis_title": "An√°lise Explorat√≥ria de Dados",
        "analysis_subtitle": "A visualizar o dataset Kepler para descobrir padr√µes e entender a base sobre a qual a nossa IA foi treinada.",
        "analysis_chart1_title": "Disposi√ß√µes de Exoplanetas no Dataset",
        "analysis_chart1_desc": """
        Este gr√°fico de barras mostra a distribui√ß√£o das tr√™s classes principais no nosso dataset. Podemos observar um desequil√≠brio de classes significativo:
        - **Falsos Positivos** s√£o a classe mais comum, o que √© esperado. A grande maioria dos sinais detetados pelos telesc√≥pios n√£o s√£o planetas reais.
        - **Candidatos** representam uma por√ß√£o menor, mas ainda significativa, de sinais promissores.
        - **Planetas Confirmados** s√£o a classe mais rara, pois exigem uma verifica√ß√£o extensiva.
        Este desequil√≠brio √© uma raz√£o fundamental pela qual t√©cnicas como o SMOTE foram usadas durante o treino da IA para garantir que ela aprende a identificar eficazmente as classes raras.
        """,
        "analysis_chart2_title": "Per√≠odo Orbital vs. Raio Planet√°rio",
        "analysis_chart2_desc": """
        Este gr√°fico de dispers√£o revela a rela√ß√£o entre o "ano" de um planeta (per√≠odo orbital) e o seu tamanho (raio). Ambos os eixos est√£o em escala logar√≠tmica para melhor visualizar a vasta gama de valores.
        - Podemos ver um denso aglomerado de planetas com per√≠odos orbitais curtos (menos de 100 dias), que s√£o mais f√°ceis de detetar porque transitam pela sua estrela com mais frequ√™ncia.
        - N√£o existe uma rela√ß√£o linear simples, indicando que planetas de todos os tamanhos podem ser encontrados a v√°rias dist√¢ncias das suas estrelas. Os planetas confirmados, representados por uma das cores na legenda, est√£o espalhados pelo gr√°fico, destacando a diversidade dos mundos descobertos.
        """,
        "analysis_chart3_title": "Distribui√ß√£o das Temperaturas de Equil√≠brio Estelar",
        "analysis_chart3_desc": """
        Este histograma exibe a frequ√™ncia de diferentes temperaturas efetivas estelares no dataset. Esta temperatura √© um indicador do tipo de estrela que est√° a ser observada.
        - A distribui√ß√£o atinge o pico por volta de 5500-6000 Kelvin, o que √© muito semelhante ao nosso Sol (~5,778 K). Isto indica que a miss√£o Kepler foi particularmente eficaz na observa√ß√£o de estrelas do tipo solar (estrelas da sequ√™ncia principal do tipo G).
        - Este foco √© parcialmente intencional, uma vez que as estrelas do tipo solar s√£o de grande interesse na busca por exoplanetas potencialmente habit√°veis.
        """,
        "analysis_chart4_title": "O Que a IA Considera Mais Importante?",
        "analysis_chart4_desc": """
        Este gr√°fico exibe a **import√¢ncia das caracter√≠sticas** (feature importances) conforme determinado pelo nosso modelo XGBoost treinado. Essencialmente, mostra em quais colunas de dados a IA mais se baseia para tomar a sua decis√£o de classifica√ß√£o.
        - N√£o surpreendentemente, o `koi_score` (uma pontua√ß√£o pr√©-calculada da probabilidade de um sinal ser um planeta) √© a caracter√≠stica mais influente.
        - As v√°rias `koi_fpflag` (Bandeiras de Falso Positivo) tamb√©m s√£o altamente importantes. Estas s√£o bandeiras atribu√≠das pelo pipeline do Kepler que indicam se um sinal se assemelha a tipos conhecidos de falsos positivos.
        - Ao visualizar isto, ganhamos confian√ßa no nosso modelo, pois confirma que a IA est√° a focar-se nas vari√°veis cientificamente mais relevantes para distinguir planetas reais de impostores.
        """,
        "analysis_chart1_xlabel": "Classe de Disposi√ß√£o",
        "analysis_chart1_ylabel": "N√∫mero de Amostras",
        "analysis_chart2_xlabel": "Per√≠odo Orbital [escala log, dias]",
        "analysis_chart2_ylabel": "Raio Planet√°rio [escala log, raios terrestres]",
        "analysis_chart3_xlabel": "Temperatura de Equil√≠brio [K]",
        "analysis_chart3_ylabel": "Frequ√™ncia",
        "analysis_chart4_xlabel": "Pontua√ß√£o de Import√¢ncia",
        "analysis_chart4_ylabel": "Nome da Caracter√≠stica",

        # ... Textos do Guia de Refer√™ncia
        "ref_title": "Guia de Refer√™ncia: A Entender os Exoplanetas e a Nossa IA",
        "ref_pipeline_title": "Como Funciona a Nossa IA? O Pipeline Passo a Passo",
        "ref_pipeline_text": """
        Para garantir que cada novo dado seja analisado de forma consistente e precisa, a nossa IA utiliza um **Pipeline de Machine Learning**. Esta √© uma sequ√™ncia de passos automatizados que processam os dados desde a sua forma bruta at√© uma previs√£o final. Eis como funciona:
        
        **Durante o Treino (o que fizemos uma vez):**
        1.  **Ingest√£o e Unifica√ß√£o de Dados:** Carreg√°mos dados de m√∫ltiplas miss√µes da NASA (Kepler, K2, TESS) e fundimo-los num √∫nico e massivo conjunto de dados.
        2.  **Prepara√ß√£o e Divis√£o:** Separamos os dados em caracter√≠sticas (as entradas, ex: `koi_period`) e o alvo (a sa√≠da que queremos prever, `disposition`). Estes dados foram ent√£o divididos num conjunto de treino (para ensinar a IA) e num conjunto de teste (para a avaliar).
        3.  **Pr√©-processamento:** Os dados de treino passaram por um rigoroso processo de "tratamento":
            - **Imputa√ß√£o:** Preencheu quaisquer pontos de dados em falta usando o valor mediano de cada coluna.
            - **Codifica√ß√£o de R√≥tulos (Label Encoding):** Converteu r√≥tulos de texto ('Candidato', 'Confirmado') em n√∫meros (0, 1, 2) que o modelo consegue entender.
            - **SMOTE (Balanceamento):** Como os planetas 'Confirmados' s√£o raros, esta t√©cnica criou exemplos sint√©ticos inteligentes das classes raras para evitar que a IA ficasse viciada em 'Falsos Positivos'.
            - **Normaliza√ß√£o (Scaling):** Normalizou todas as caracter√≠sticas num√©ricas para uma escala comum, garantindo que nenhuma caracter√≠stica pudesse dominar injustamente o processo de aprendizagem.
        4.  **Treino do Modelo:** O nosso modelo principal, um **Classificador XGBoost**, foi treinado com estes dados totalmente pr√©-processados.
        5.  **Serializa√ß√£o de Artefactos:** Guard√°mos n√£o s√≥ o modelo treinado, mas *todos os componentes* do pipeline de pr√©-processamento (o imputer, o scaler, o codificador de r√≥tulos e a lista de colunas). Estes s√£o os 'artefactos'.

        **Durante a Previs√£o (o que acontece sempre que clica em 'Classificar'):**
        1.  **Carregar Artefactos:** A aplica√ß√£o carrega todos os componentes guardados do pipeline.
        2.  **Aplicar Pipeline Id√™ntico:** Os seus novos dados passam pela mesma sequ√™ncia exata de passos, usando os componentes j√° ajustados:
            - O **imputer ajustado** preenche os valores em falta com base nas medianas dos dados originais.
            - O **scaler ajustado** normaliza os seus dados com base na escala dos dados originais.
            - O **modelo XGBoost treinado** recebe os dados totalmente processados e faz uma previs√£o.
            - O **codificador de r√≥tulos ajustado** traduz a sa√≠da num√©rica do modelo de volta para um r√≥tulo leg√≠vel por humanos ('Candidato', 'Confirmado' ou 'Falso Positivo').
            
        Este processo rigoroso e repet√≠vel garante que cada previs√£o √© feita com o mesmo rigor e l√≥gica que foram usados para treinar e validar a IA.
        """,
        "ref_performance_title": "Performance da Nossa IA",
        "ref_performance_text": """
        Para garantir que o nosso modelo √© fi√°vel, ele foi rigorosamente avaliado num conjunto de dados de teste separado que nunca tinha visto durante o treino. Com base na avalia√ß√£o final no nosso notebook de treino, o modelo alcan√ßou:
        - **Precis√£o Geral: 98.46%**
        Esta alta pontua√ß√£o de precis√£o significa que o modelo √© extremamente eficaz na classifica√ß√£o correta de sinais nas categorias 'Confirmado', 'Candidato' e 'Falso Positivo'. Este n√≠vel de performance √© crucial para filtrar eficientemente grandes quantidades de dados para encontrar sinais genu√≠nos de exoplanetas.
        """,
        "ref_what_are_exoplanets_title": "O que s√£o Exoplanetas?",
        "ref_what_are_exoplanets_text": """
        Um exoplaneta √© qualquer planeta para al√©m do nosso sistema solar. Eles existem numa grande variedade de tamanhos e √≥rbitas. Alguns s√£o gigantes gasosos gigantescos muito pr√≥ximos da sua estrela-m√£e, outros s√£o gelados, e alguns s√£o rochosos, como a Terra. Em 2024, mais de 5,000 exoplanetas foram encontrados. Os tipos principais incluem:
        - **Gigantes Gasosos:** Grandes planetas compostos maioritariamente por h√©lio e/ou hidrog√©nio, como J√∫piter e Saturno.
        - **Super-Terras:** Uma classe de planetas com uma massa superior √† da Terra, mas substancialmente abaixo da dos gigantes de gelo do Sistema Solar, Urano e Neptuno.
        - **Tipo Neptuno:** Planetas de tamanho semelhante a Neptuno ou Urano, com atmosferas dominadas por hidrog√©nio/h√©lio.
        - **Terrestres:** Planetas do tamanho da Terra ou menores, compostos por rocha, silicato, √°gua ou carbono. A busca por mundos habit√°veis foca-se nesta categoria.
        """,
        "ref_how_ai_helps_title": "Como a Nossa IA Ajuda?",
        "ref_how_ai_helps_text": """
        Analisar manualmente centenas de milhares de curvas de luz √© imposs√≠vel. A nossa IA automatiza e acelera este processo. Especificamente, √© um modelo **XGBoost (Extreme Gradient Boosting)**, um poderoso algoritmo de machine learning.
        
        1.  **Reconhecimento de Padr√µes:** O modelo XGBoost √© um conjunto de "√°rvores de decis√£o". Ele aprende adicionando sequencialmente novas √°rvores que corrigem os erros das anteriores. Isto permite-lhe aprender padr√µes altamente complexos e n√£o lineares nos dados de tr√¢nsito que um olho humano n√£o detetaria.
        2.  **Import√¢ncia das Caracter√≠sticas:** Ele pode determinar qual das centenas de caracter√≠sticas (como profundidade do tr√¢nsito, raio estelar, etc.) √© mais preditiva para classificar um sinal. Podemos ver na aba 'An√°lise de Dados' que caracter√≠sticas como o `koi_score` s√£o altamente influentes.
        3.  **Velocidade e Efici√™ncia:** Uma vez treinado, o modelo pode classificar um novo candidato numa fra√ß√£o de segundo. Isto permite que os cientistas analisem eficientemente conjuntos de dados massivos de miss√µes como a TESS e priorizem os sinais mais promissores para verifica√ß√£o de acompanhamento com outros telesc√≥pios. Atua como um filtro inteligente e incrivelmente eficaz.
        """,
        "ref_dispositions_title": "A Entender as Classifica√ß√µes",
        "ref_dispositions_text": """
        - **Candidato:** Um sinal que passou nos testes automatizados iniciais e exibe caracter√≠sticas semelhantes √†s de um planeta. √â uma pista promissora, mas ainda n√£o √© um planeta confirmado. O trabalho da IA √© avaliar a for√ßa desta candidatura.
        - **Falso Positivo:** Um sinal que imita um tr√¢nsito planet√°rio, mas √© causado por outra coisa. Causas comuns incluem sistemas de estrelas bin√°rias eclipsantes (duas estrelas a orbitar-se mutuamente), manchas estelares ou ru√≠do dos instrumentos da nave espacial. Uma IA robusta √© crucial para eliminar estes com alta precis√£o.
        - **Confirmado:** Um candidato que foi verificado como um verdadeiro exoplaneta atrav√©s de observa√ß√µes de acompanhamento rigorosas, muitas vezes usando m√©todos de dete√ß√£o diferentes (como o m√©todo de velocidade radial) para confirmar a sua massa e natureza planet√°ria.
        """,
    }
}
# Adicionar chaves em falta para evitar KeyErrors
for lang in translations:
    for key, value in translations['en'].items():
        if key not in translations[lang]:
            translations[lang][key] = value
    for key, value in translations['pt'].items():
        if key not in translations[lang]:
            translations[lang][key] = value


# --- FUN√á√ïES AUXILIARES ---
@st.cache_resource(show_spinner=False)
def load_model():
    try:
        predictor = ExoplanetModel(artifacts_path='artifacts/')
        return predictor if predictor.model else None
    except Exception as e:
        st.error(f"Error loading model: {e}")
        return None

@st.cache_data(show_spinner=False)
def load_analysis_data():
    """Carrega os dados do Kepler para an√°lise e exemplos."""
    file_path = 'data/kepler.csv'
    try:
        return pd.read_csv(file_path, comment='#')
    except FileNotFoundError:
        st.error(f"File '{file_path}' not found.")
        return None

def display_classification_result(result, texts):
    if result.get('warning'): st.warning(texts['warning_ia'].format(result['warning']))
    if result.get('error'): st.error(texts['error_prediction'].format(result['error']))
    else:
        st.success(texts.get('analysis_finished', "Analysis Complete!"))
        st.subheader(texts.get('result_header', "Classification Result:"))
        prediction = result.get('prediction')
        confidence = result.get('confidence', {})
        class_map = {
            "Confirmed": f"## ü™ê <span style='color:green;'>{texts.get('class_confirmed', 'Confirmed')}</span>",
            "Candidate": f"## üî≠ <span style='color:blue;'>{texts.get('class_candidate', 'Candidate')}</span>",
            "False Positive": f"## ‚òÑÔ∏è <span style='color:red;'>{texts.get('class_false_positive', 'False Positive')}</span>"
        }
        st.markdown(class_map.get(prediction, f"## {prediction}"), unsafe_allow_html=True)
        st.subheader(texts.get('confidence_header', "Confidence Level:"))
        c1, c2, c3 = st.columns(3)
        c1.metric(texts.get('class_candidate', 'Candidate'), f"{confidence.get('Candidate', 0):.1%}")
        c2.metric(texts.get('class_confirmed', 'Confirmed'), f"{confidence.get('Confirmed', 0):.1%}")
        c3.metric(texts.get('class_false_positive', 'False Positive'), f"{confidence.get('False Positive', 0):.1%}")

# --- P√ÅGINAS DA APLICA√á√ÉO ---
def render_classifier_page(predictor, texts):
    st.title(texts['classifier_title'])
    tab1, tab2 = st.tabs([texts['classifier_tab_file'], texts['classifier_tab_manual']])
    with tab1:
        uploaded_file = st.file_uploader(texts['file_uploader_label'], type="csv", key="file_uploader")
        if st.button(texts['example_button']):
            df = load_analysis_data()
            if df is not None:
                st.session_state.sample = df.sample(1)
                st.success(texts.get('example_success', 'Success!'))
        input_df = None
        if uploaded_file:
            st.session_state.sample = None
            try:
                input_df = pd.read_csv(uploaded_file)
                st.write(texts.get('sample_data_header', 'Data sample:'))
                st.dataframe(input_df.head())
            except Exception as e:
                st.error(texts.get('file_read_error', 'Error reading file').format(e))
        elif 'sample' in st.session_state and st.session_state.sample is not None:
            input_df = st.session_state.sample
            st.write(texts.get('example_data_header', 'Example data:'))
            st.dataframe(input_df)
        if input_df is not None and st.button(texts['classify_file_button']):
            with st.spinner(texts.get('spinner_text', 'Analyzing...')):
                display_classification_result(predictor.predict(input_df.iloc[[0]]), texts)
    with tab2:
        submitted = False
        with st.form(key="manual_input_form"):
            st.header(texts['manual_header'])
            c1, c2, c3 = st.columns(3)
            with c1:
                koi_score = st.number_input(texts['form_koi_score'], value=0.9, format="%.4f")
                koi_period = st.number_input(texts['form_koi_period'], value=5.0, format="%.4f")
            with c2:
                koi_prad = st.number_input(texts['form_koi_prad'], value=1.5, format="%.2f")
                koi_duration = st.number_input(texts['form_koi_duration'], value=3.0, format="%.4f")
            with c3:
                koi_depth = st.number_input(texts['form_koi_depth'], value=100.0, format="%.2f")
                koi_teq = st.number_input(texts['form_koi_teq'], value=300, format="%d")
            submitted = st.form_submit_button(texts['classify_manual_button'])

        if submitted:
            manual_data = pd.DataFrame([{'koi_score': koi_score, 'koi_period': koi_period, 'koi_prad': koi_prad, 'koi_duration': koi_duration, 'koi_depth': koi_depth, 'koi_teq': koi_teq}])
            with st.spinner(texts.get('spinner_text', 'Analyzing...')):
                display_classification_result(predictor.predict(manual_data), texts)

def render_analysis_page(predictor, texts):
    st.title(texts['analysis_title'])
    st.markdown(texts['analysis_subtitle'])
    
    df = load_analysis_data()
    
    if df is not None:
        st.subheader(texts['analysis_chart1_title'])
        st.markdown(texts['analysis_chart1_desc'])
        fig1, ax1 = plt.subplots()
        sns.countplot(data=df, x='koi_disposition', ax=ax1, order=df['koi_disposition'].value_counts().index)
        ax1.set_xlabel(texts.get('analysis_chart1_xlabel'))
        ax1.set_ylabel(texts.get('analysis_chart1_ylabel'))
        st.pyplot(fig1)
        
        st.subheader(texts['analysis_chart2_title'])
        st.markdown(texts['analysis_chart2_desc'])
        fig2, ax2 = plt.subplots(figsize=(10, 6))
        sns.scatterplot(data=df, x='koi_period', y='koi_prad', hue='koi_disposition', alpha=0.5, ax=ax2)
        ax2.set_xscale('log')
        ax2.set_yscale('log')
        ax2.set_xlabel(texts.get('analysis_chart2_xlabel'))
        ax2.set_ylabel(texts.get('analysis_chart2_ylabel'))
        st.pyplot(fig2)

        st.subheader(texts['analysis_chart3_title'])
        st.markdown(texts['analysis_chart3_desc'])
        fig3, ax3 = plt.subplots()
        sns.histplot(df['koi_steff'].dropna(), kde=True, ax=ax3, bins=50)
        ax3.set_xlabel(texts.get('analysis_chart3_xlabel'))
        ax3.set_ylabel(texts.get('analysis_chart3_ylabel'))
        st.pyplot(fig3)
        
        st.subheader(texts['analysis_chart4_title'])
        st.markdown(texts['analysis_chart4_desc'])
        try:
            importances = predictor.model.feature_importances_
            # CORRE√á√ÉO: Usar a fonte mais robusta para os nomes das caracter√≠sticas
            if hasattr(predictor.imputer, 'get_feature_names_out'):
                 feature_names = predictor.imputer.get_feature_names_out()
            else: # Fallback para vers√µes mais antigas
                 feature_names = predictor.columns

            # Verifica√ß√£o de seguran√ßa para garantir que os comprimentos correspondem
            if len(importances) == len(feature_names):
                importance_df = pd.DataFrame({'feature': feature_names, 'importance': importances})
                importance_df = importance_df.sort_values('importance', ascending=False).head(20)
                
                fig4, ax4 = plt.subplots(figsize=(10, 8))
                sns.barplot(x='importance', y='feature', data=importance_df, ax=ax4)
                ax4.set_xlabel(texts.get('analysis_chart4_xlabel'))
                ax4.set_ylabel(texts.get('analysis_chart4_ylabel'))
                st.pyplot(fig4)
            else:
                 st.warning("Could not display feature importance chart due to a length mismatch between features and importances.")

        except Exception as e:
            st.warning(f"Could not display feature importance chart. Error: {e}")

    else:
        st.error("Kepler dataset not found. Cannot display analysis.")

def render_reference_page(texts):
    st.title(texts.get('ref_title', "Reference"))

    st.header(texts.get('ref_pipeline_title'))
    st.markdown(texts.get('ref_pipeline_text'))
    
    st.header(texts.get('ref_performance_title'))
    st.markdown(texts.get('ref_performance_text'))

    st.header(texts.get('ref_what_are_exoplanets_title'))
    st.markdown(texts.get('ref_what_are_exoplanets_text'))

    st.header(texts.get('ref_how_ai_helps_title'))
    st.markdown(texts.get('ref_how_ai_helps_text'))
    
    st.header(texts.get('ref_dispositions_title'))
    st.markdown(texts.get('ref_dispositions_text'))

# --- L√ìGICA PRINCIPAL DA APLICA√á√ÉO ---
if 'lang' not in st.session_state: 
    if 'lang' in st.query_params:
        st.session_state.lang = st.query_params['lang']
    else:
        st.session_state.lang = 'en'


# CORRE√á√ÉO: L√≥gica de Bot√£o para Troca de Idioma
def set_language(lang_code):
    st.session_state.lang = lang_code

st.sidebar.markdown(f"""
<div class="language-selector">
  <button class="language-button">{translations[st.session_state.lang]['lang_current']}</button>
  <div class="language-dropdown">
     <!-- Esta parte √© agora apenas visual, a l√≥gica est√° nos bot√µes abaixo -->
  </div>
</div>
""", unsafe_allow_html=True)

if st.sidebar.button(translations[st.session_state.lang]['lang_switch_to']):
    set_language(translations[st.session_state.lang]['lang_switch_code'])
    st.rerun()


texts = translations[st.session_state.lang]

predictor = load_model()

st.sidebar.title(texts['sidebar_title'])
st.sidebar.write(texts['sidebar_subtitle'])
st.sidebar.markdown("---")
app_mode = st.sidebar.selectbox(
    texts['sidebar_select_mode'],
    [texts['mode_classifier'], texts['mode_analysis'], texts['mode_reference']]
)

if predictor:
    if app_mode == texts['mode_classifier']: render_classifier_page(predictor, texts)
    elif app_mode == texts['mode_analysis']: render_analysis_page(predictor, texts) # Passar o predictor
    elif app_mode == texts['mode_reference']: render_reference_page(texts)
else:
    st.error("CRITICAL: AI model could not be loaded. The application cannot continue.")